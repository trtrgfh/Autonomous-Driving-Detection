<img src="https://github.com/trtrgfh/YOLO-Autonomous-Driving-Detection/assets/73056232/5aad6c93-5e85-421f-98a4-6b240e6cc1bc" width="500"/>

# Autonomous Driving Detection

# Project Overview
The objective of this project is to implement You Only Look Once (YOLO), a state-of-the-art object detection algorithm, for detecting objects in the context of autonomous driving. The focus will be on identifying and tracking vehicles, pedestrians, cyclists, and other relevant objects on the road.

# Installation and Setup
## Python Packages Used
- **General Purpose:** os
- **Data Manipulation:** numpy, pandas, scipy
- **Data Visualization:** matplotlib, PIL, colorsys
- **Machine Learning:** tensorflow, tensorflow.keras

# Data
Dataset used can be found in the images foleder which contains 720x1280 RGB images. Since YOLO's network was trained on 608x608 images, the bounding boxes need to be rescaled so that they can be plotted on top of the original 720x1280 image.

# Results and evaluation
<img src="https://github.com/trtrgfh/YOLO-Autonomous-Driving-Detection/assets/73056232/1f58036e-928c-4c9e-9bed-ec84b6c2f958" width="700"/>

<img src="https://github.com/trtrgfh/YOLO-Autonomous-Driving-Detection/assets/73056232/e28f1253-d531-4932-9d63-0edb7f3f259f" width="700"/>

